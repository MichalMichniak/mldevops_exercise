{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyM1kTZAuxBki0GgfwnvO1di",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MichalMichniak/Sieci-Neuronowe/blob/main/Lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Us7hatASFXdT"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ],
   "metadata": {
    "id": "sosIvV_8GsrY",
    "outputId": "b002f49f-06e3-4786-cd6c-265804b4ae0c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 12370475.21it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 212071.95it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4422102/4422102 [00:06<00:00, 696995.56it/s] \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 24125449.15it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ],
   "metadata": {
    "id": "ycYaWwZGH6xl"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(train_dataloader.dataset.data.shape)"
   ],
   "metadata": {
    "id": "NDEo5znCIbun",
    "outputId": "11aa7171-b6d1-4a8a-abc9-52b47cd4233c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simple ANN"
   ],
   "metadata": {
    "id": "_SfLM8hJW2wN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class NN:\n",
    "    def __init__(self):\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(12544, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 64),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def validate_model(self, test_dataloader, device):\n",
    "        self.model.eval()  # Ustaw model w tryb ewaluacji\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():  # Wyłączenie obliczania gradientów\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)  # Wybór klasy z najwyższym prawdopodobieństwem\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    def train_model(self, train_dataloader, test_dataloader, num_epochs=10, learning_rate=0.001):\n",
    "        # Użycie GPU jeśli dostępne\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Zdefiniowanie optymalizatora i funkcji straty\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()  # Użycie CrossEntropyLoss dla klasyfikacji\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()  # Ustaw model w tryb treningowy\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for inputs, labels in tqdm(train_dataloader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Zerowanie gradientów\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Walidacja na końcu każdej epoki\n",
    "            self.validate_model(test_dataloader, device)\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}\")"
   ],
   "metadata": {
    "id": "y2968dl7IPwD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(NN().model)"
   ],
   "metadata": {
    "id": "REvtOV2zJuik",
    "outputId": "388a603e-f397-4473-9e50-69d28fb560f3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU()\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Flatten(start_dim=1, end_dim=-1)\n",
      "  (6): Linear(in_features=12544, out_features=512, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=512, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = NN()\n",
    "model.train_model(train_dataloader, test_dataloader, num_epochs=10, learning_rate=0.001)"
   ],
   "metadata": {
    "id": "R3NONg6nJ7Ga",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eefc21f8-1f22-4489-a7b3-b99cd0181013"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 76.70it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 88.64%\n",
      "Epoch [1/10], Loss: 0.3859\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 73.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 90.38%\n",
      "Epoch [2/10], Loss: 0.2253\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 77.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 90.40%\n",
      "Epoch [3/10], Loss: 0.1661\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 77.61it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 91.23%\n",
      "Epoch [4/10], Loss: 0.1187\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 77.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 91.41%\n",
      "Epoch [5/10], Loss: 0.0796\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 77.26it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 91.14%\n",
      "Epoch [6/10], Loss: 0.0585\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 76.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 91.53%\n",
      "Epoch [7/10], Loss: 0.0446\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 76.95it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 91.81%\n",
      "Epoch [8/10], Loss: 0.0324\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 77.17it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 92.00%\n",
      "Epoch [9/10], Loss: 0.0268\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:12<00:00, 77.31it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy: 92.43%\n",
      "Epoch [10/10], Loss: 0.0217\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Autoencoder"
   ],
   "metadata": {
    "id": "fvti-BejWraX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Autoenc:\n",
    "    def __init__(self):\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(12544, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 12),\n",
    "        ).to(device)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(12, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 12544),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (64, 14, 14)),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "    def validate_model(self, test_dataloader, device):\n",
    "        self.encoder.eval()  # Ustaw model w tryb ewaluacji\n",
    "        self.decoder.eval()\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        with torch.no_grad():  # Wyłączenie obliczania gradientów\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = self.forward(inputs)\n",
    "                running_loss += nn.MSELoss()(outputs, inputs).item()\n",
    "\n",
    "        meanloss = running_loss / len(test_dataloader)\n",
    "        print(f\"Validation Loss: {meanloss:.2f}\")\n",
    "\n",
    "    def train_model(self, train_dataloader, test_dataloader, num_epochs=10, learning_rate=0.001):\n",
    "        # Użycie GPU jeśli dostępne\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Zdefiniowanie optymalizatora i funkcji straty\n",
    "        optimizer = optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()  # Użycie CrossEntropyLoss dla klasyfikacji\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.encoder.train()  # Ustaw model w tryb treningowy\n",
    "            self.decoder.train()\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for inputs, labels in tqdm(train_dataloader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Zerowanie gradientów\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = nn.MSELoss()(outputs, inputs)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Walidacja na końcu każdej epoki\n",
    "            self.validate_model(test_dataloader, device)\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}\")"
   ],
   "metadata": {
    "id": "1Gd6UsxUWvhK"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Autoenc()\n",
    "model.train_model(train_dataloader, test_dataloader, num_epochs=10, learning_rate=0.001)"
   ],
   "metadata": {
    "id": "PJwA_Mi2YKrP",
    "outputId": "82f3115e-9f58-4215-e14f-41c307b1d6c7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:17<00:00, 54.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [1/10], Loss: 0.0187\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 59.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [2/10], Loss: 0.0119\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.66it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [3/10], Loss: 0.0110\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [4/10], Loss: 0.0104\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:24<00:00, 37.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [5/10], Loss: 0.0101\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.33it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [6/10], Loss: 0.0098\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.85it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [7/10], Loss: 0.0096\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 57.06it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [8/10], Loss: 0.0094\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:15<00:00, 60.75it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [9/10], Loss: 0.0093\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 938/938 [00:16<00:00, 55.64it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 0.01\n",
      "Epoch [10/10], Loss: 0.0091\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_vector = torch.randn(1, 12).to(device)\n",
    "\n",
    "decoded_image = model.decoder(random_vector)\n",
    "\n",
    "decoded_image = decoded_image.reshape(28, 28).detach().cpu().numpy()\n",
    "\n",
    "plt.imshow(decoded_image, cmap=\"gray\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "Piq92gR6OGC1"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}